{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from rapidfuzz import process, fuzz\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### KEYWORDS #####\n",
    "\n",
    "### category_name : [LABELS]\n",
    "\n",
    "categories = {\n",
    "    'APP': ['threshold', 'above a rating'],\n",
    "    'Ave': ['high average', 'average rating', 'average score'],\n",
    "    'ADD': ['sum', 'add up'],\n",
    "    'MPL': ['highest rating', 'overall highest', 'liked the most'],\n",
    "    'Div': ['diversity', 'wide range', 'high variance', 'spread', 'diverse'],\n",
    "    'Sim': ['similar user', 'similar rating', 'similar group', 'similar taste', 'similar item'],\n",
    "    'Pop': ['liked by multiple users', 'rated highly by multiple', 'many users have given high ratings to',\n",
    "                              'generally high rating', 'highly rated', 'consistently high','high ratings across','popular'],\n",
    "    'LMS': ['highest of lowest values']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    '''Lemmatization and lowercase of explanations to handle text'''\n",
    "    doc = nlp(text.lower())  \n",
    "    return \" \".join([lemmatizer.lemmatize(token.text) for token in doc])\n",
    "\n",
    "def extract_numbers(text):\n",
    "    '''Number extraction'''\n",
    "    return [int(num) for num in re.findall(r'\\b\\d+\\b', text)]\n",
    "\n",
    "def is_negated(text, keyword):\n",
    "    '''explicit negation check\n",
    "    Important to find instances of 'I did not average', I recommend without averaging etc.\n",
    "    '''\n",
    "    pattern = r'\\b(not|never|without|did\\snot)\\s+' + re.escape(keyword) + r'\\b'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "def fuzzy_match(text, category_keywords, threshold=85):\n",
    "    '''fuzzy match similarity '''\n",
    "    for keyword in category_keywords:\n",
    "        if fuzz.partial_ratio(text, keyword) >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def categorize_explanation(text):\n",
    "    '''Main function\n",
    "    \n",
    "    - preprocess explanation + keywords\n",
    "    - search for numbers, search for negation\n",
    "    - fuzzy search for keywords\n",
    "    \n",
    "    '''\n",
    "    if pd.isna(text):  \n",
    "        return \"N/A\"\n",
    "    \n",
    "    text = preprocess_text(text)  # preproc\n",
    "    \n",
    "    matched_categories = set()\n",
    "    \n",
    "    for category, keywords in categories.items():\n",
    "        for keyword in keywords:\n",
    "            keyword = preprocess_text(keyword) \n",
    "            \n",
    "            ## check for numbers \n",
    "            if re.search(r'\\b\\d+\\b', keyword):  \n",
    "                text_nums = extract_numbers(text)\n",
    "                keyword_nums = extract_numbers(keyword)\n",
    "                if text_nums and keyword_nums:\n",
    "                    if all(t >= k for t, k in zip(text_nums, keyword_nums)):  \n",
    "                        matched_categories.add(category)\n",
    "                        break\n",
    "            \n",
    "            \n",
    "            if fuzzy_match(text, [keyword]):\n",
    "                if is_negated(text, keyword):\n",
    "                    break  # Skip if negated\n",
    "                matched_categories.add(category)\n",
    "                break  \n",
    "\n",
    "    # exclusion rules. Some categories are defined in a contradicting manner and should not be combined. If averaging but also mentioned some other popularity keyword, it is not undefined anymore.\n",
    "    if 'Pop' in matched_categories and ('Ave' in matched_categories or 'App' in matched_categories):\n",
    "        matched_categories.remove('Pop')\n",
    "\n",
    "\n",
    "    if 'ADD' in matched_categories and 'Ave' in matched_categories:\n",
    "        matched_categories.remove('ADD')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return ', '.join(matched_categories) if matched_categories else \"Other\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLY CATEGORIZATION FUNCTION ##\n",
    "\n",
    "## First get all explanations\n",
    "e25 = pd.read_csv('your_file_containing_explanations_25item_groups')\n",
    "e50 = pd.read_csv('your_file_containing_explanations_50item_groups')\n",
    "e75 = pd.read_csv('your_file_containing_explanations_75item_groups')\n",
    "\n",
    "## add indication of item count in group\n",
    "e25['Item_Group'] = '25 items'\n",
    "e50['Item_Group'] = '50 items'\n",
    "e75['Item_Group'] = '75 items'\n",
    "\n",
    "\n",
    "# combine all data\n",
    "e_comb = pd.concat([e25, e50, e75])\n",
    "\n",
    "## long form data\n",
    "e_m =  pd.melt(e_comb, \n",
    "                    id_vars=['groupId', 'Item_Group'], \n",
    "                    value_vars=['Llama', 'Mistral', 'Gemma', 'Phi'], \n",
    "                    var_name='Model', \n",
    "                    value_name='Exp')\n",
    "e_m['id'] = e_m.index + 1\n",
    "\n",
    "\n",
    "\n",
    "## APPLY ACTUAL CATEGORIZATION TO ALL EXPLANATIONS\n",
    "e_m['labels'] = e_m['Exp'].apply(categorize_explanation)\n",
    "\n",
    "\n",
    "# have a look\n",
    "e_m.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE RESULTS AS SHOWN IN TABLE ####\n",
    "\n",
    "#Explode labels to count occurrences \n",
    "e_m_exploded = e_m.assign(label=e_m['labels'].str.split(', ')).explode('label')\n",
    "\n",
    "# Count occurrences of each label per model and item group\n",
    "label_counts = e_m_exploded.groupby(['Model', 'Item_Group', 'label']).size().reset_index(name='count')\n",
    "\n",
    "# pivot to get table as we want\n",
    "label_counts_pivot = label_counts.pivot_table(index=['label', 'Item_Group'], columns='Model', values='count', fill_value=0)\n",
    "\n",
    "# percentages \n",
    "label_counts_pivot_percent = (label_counts_pivot / 500) * 100\n",
    "label_counts_pivot_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
