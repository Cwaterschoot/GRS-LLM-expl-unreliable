{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "import random\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "import ast\n",
    "import os\n",
    "from enum import Enum\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import collections as c\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import ast\n",
    "\n",
    "random.seed(123456) \n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_18154</th>\n",
       "      <th>item_27769</th>\n",
       "      <th>item_6453</th>\n",
       "      <th>item_47239</th>\n",
       "      <th>item_6557</th>\n",
       "      <th>item_13201</th>\n",
       "      <th>item_79785</th>\n",
       "      <th>item_67012</th>\n",
       "      <th>item_16798</th>\n",
       "      <th>...</th>\n",
       "      <th>item_9390</th>\n",
       "      <th>item_21333</th>\n",
       "      <th>item_11624</th>\n",
       "      <th>item_59952</th>\n",
       "      <th>item_13193</th>\n",
       "      <th>item_25125</th>\n",
       "      <th>item_55990</th>\n",
       "      <th>item_90364</th>\n",
       "      <th>item_4403</th>\n",
       "      <th>groupId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4856</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_33653</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>53</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_18154  item_27769  item_6453  item_47239  item_6557  \\\n",
       "0   user_4856          23           1         85          10          7   \n",
       "1  user_33653          65          80         66          89         93   \n",
       "\n",
       "   item_13201  item_79785  item_67012  item_16798  ...  item_9390  item_21333  \\\n",
       "0          35           4          15          30  ...         52          32   \n",
       "1          15          95          51          36  ...         18          89   \n",
       "\n",
       "   item_11624  item_59952  item_13193  item_25125  item_55990  item_90364  \\\n",
       "0           2          78          66          56          16          78   \n",
       "1          53          16          38          35          43          32   \n",
       "\n",
       "   item_4403  groupId  \n",
       "0         67     5001  \n",
       "1         41     5001  \n",
       "\n",
       "[2 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading datasets\n",
    "\n",
    "####################\n",
    "total = 2000\n",
    "num_members = [4]\n",
    "\n",
    "\n",
    "num_items = [75]  #### [either 25, 50 or 75]\n",
    "##################\n",
    "## Datasets are named after num_members, num_items and total groups\n",
    "\n",
    "\n",
    "#file = f'group_data/v2-groups_{num_members}members_{num_items}items_totalgroups{total}.csv'\n",
    "file = f'v3-groups_{num_members}members_{num_items}items_totalgroups{total}.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df.head(2) ## example users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All helper functions + aggregation strategy implementations\n",
    "\n",
    "def transform_df(df):\n",
    "    df_long = df.melt(id_vars=['groupId', 'user_id'], var_name='item', value_name='rating')\n",
    "    return df_long\n",
    "\n",
    "def listmaker(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            value = [value]\n",
    "        except (ValueError, SyntaxError):\n",
    "            print(f\"ERROR MAKING A LIST?!\")\n",
    "            return []  \n",
    "    return value if isinstance(value, list) else []  \n",
    "\n",
    "\n",
    "def ADD(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].sum().reset_index(name='sum_rating')\n",
    "    return list(counts.sort_values(by='sum_rating', ascending=False)['item'].head(10))\n",
    "    \n",
    "\n",
    "def APP(df, threshold=60):\n",
    "    above_threshold = df[df['rating'] > threshold]\n",
    "    counts = above_threshold.groupby(['groupId', 'item']).size().reset_index(name='count_above_threshold')\n",
    "    \n",
    "    all_items = df['item'].unique()\n",
    "    all_groups = df['groupId'].unique()\n",
    "    full_index = pd.MultiIndex.from_product([all_groups, all_items], names=['groupId', 'item'])\n",
    "    \n",
    "    counts = counts.set_index(['groupId', 'item']).reindex(full_index, fill_value=0).reset_index()\n",
    "    \n",
    "    return list(counts.sort_values(by='count_above_threshold', ascending=False)['item'].head(10))\n",
    "\n",
    "def LMS(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].min().reset_index(name='min_rating')\n",
    "    return list(counts.sort_values(by='min_rating', ascending=False)['item'].head(10))\n",
    "\n",
    "def MPL(df):\n",
    "    counts = df.groupby(['groupId', 'item'])['rating'].max().reset_index(name='max_rating')\n",
    "    \n",
    "    return list(counts.sort_values(by='max_rating', ascending=False)['item'].head(10))\n",
    "\n",
    "\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def cosine_sim(vector1, vector2):\n",
    "    return float(dot(vector1, vector2)/(norm(vector1)*norm(vector2)))        \n",
    "\n",
    "def clean_model_list(val):\n",
    "    \n",
    "    if isinstance(val, list):\n",
    "        cleaned_list = []\n",
    "        for item in val:\n",
    "            cleaned_list.extend(clean_model_list(item))  \n",
    "        return cleaned_list\n",
    "    \n",
    "    if isinstance(val, str):\n",
    "        if val.startswith('[\"') and val.endswith('\"]'):\n",
    "            return [val[2:-2]]  \n",
    "        \n",
    "        try:\n",
    "            evaluated = ast.literal_eval(val)\n",
    "            if isinstance(evaluated, list):\n",
    "                return clean_model_list(evaluated)  \n",
    "        except (SyntaxError, ValueError):\n",
    "            pass  \n",
    "    \n",
    "        if ',' in val:\n",
    "            return [item.strip() for item in val.split(',')]\n",
    "    \n",
    "    return [str(val)]\n",
    "\n",
    "\n",
    "def ensure_list(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            value = ast.literal_eval(value)  \n",
    "        except (ValueError, SyntaxError):\n",
    "            print(f\"Warning: Failed to convert {value} to list\")\n",
    "            return []  \n",
    "    return value if isinstance(value, list) else []  \n",
    "\n",
    "\n",
    "def extract_numbers(items):\n",
    "    return [int(re.search(r'(\\d+)$', item).group(1)) for item in items if re.search(r'(\\d+)$', item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LLMS ######\n",
    "\n",
    "\n",
    "## Load LLMs themselves\n",
    "llm_llama = ChatOllama(model='llama3.1:8b-instruct-q8_0', temperature=0.1, max_tokens=1000,seed=1234) \n",
    "llm_mistral = ChatOllama(model='mistral-nemo:12b-instruct-2407-q4_K_M', temperature=0.1, max_tokens=1000,seed=1234) \n",
    "llm_gemma = ChatOllama(model='gemma3:12b', temperature=0.1, max_tokens=1000,seed=1234) \n",
    "llm_phi = ChatOllama(model='phi4', temperature=0.1, max_tokens=1000,seed=1234) \n",
    "\n",
    "## Parser to double check JSON ##\n",
    "class RecommendationExpl(BaseModel):\n",
    "    recommendation: list = Field(description=\"python list of the final group recommendations\")\n",
    "    explanation: str = Field(description='your explanation of your recommendation procedure')\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=RecommendationExpl)\n",
    "\n",
    "\n",
    "### Prompt itself #####\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "\n",
    "    You are an expert in making and explaining group recommendations based on the knowledge base provided below. You do not write python code.\n",
    "    You explain the process behind making the recommendation to the group in such a way that someone without recommender systems knowledge can understand. Come up with a simple way to explain to the group how you came up with your recommendations.\n",
    "    That information includes users (user_id) and information on items they like (item_x). \n",
    "    The rating is a scale from 0 to 100. When referring to items, use item_value. The userId itself is just to refer to a user. For the recommendation, you simply mention the item.\n",
    "\n",
    "    The per-item ratings are presente below: \\n\n",
    "    ## begin ratings ##\n",
    "    {desc}\n",
    "    ## end ratings ##\n",
    "    \n",
    "    You make a recommendation to this group of users by providing 10 items based on your recommendation approach. \n",
    "    Your recommendation contains exactly 10 items and is formatted as a python list containing strings. Refer to items using their name (item_value)\n",
    "    \n",
    "    Provide your answer strictly as a JSON object with the following format:\n",
    "{{\n",
    "  \"recommendation\": [\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\",\"item\"],\n",
    "  \"explanation\": \"explanation and example of your recommendation procedure\"\n",
    "}}\n",
    "Think about the answer internally, but only output the final JSON object. Do not include any additional text or python code. \n",
    "\n",
    "    \"\"\" ,\n",
    "    input_variables=[\"desc\"]\n",
    ")\n",
    "\n",
    "\n",
    "#### LLM chains -> prompt | model | json parser\n",
    "\n",
    "chain_llama = prompt | llm_llama | parser\n",
    "chain_mistral = prompt | llm_mistral | parser\n",
    "chain_gemma = prompt | llm_gemma | parser\n",
    "chain_phi = prompt | llm_phi| parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## LLM LOOP ##########\n",
    "\n",
    "\n",
    "\n",
    "result_file = \"your_file_name_for_recommendations\"\n",
    "expl_file = \"your_file_name_for_explanations\"\n",
    "\n",
    "result_exists = os.path.isfile(result_file)\n",
    "expl_exists = os.path.isfile(expl_file)\n",
    "\n",
    "\n",
    "### if we do not start from scratch, continue where we previously left off\n",
    "if result_exists == True:\n",
    "    done = pd.read_csv(result_file)\n",
    "    group= done['groupId'].max() +1\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "## Otherwise start at the beginning\n",
    "else:\n",
    "    group = df['groupId'].min()\n",
    "    max_counter = df['groupId'].max()\n",
    "\n",
    "\n",
    "print(group)\n",
    "\n",
    "while group <= max_counter:\n",
    "    # Locate group\n",
    "    df_members = df.loc[df['groupId'] == group]\n",
    "\n",
    "    try:\n",
    "        \n",
    "        ## generate responses from each LLM using the group scenario. Columns -1 because the groupId is not necessary to present to LLM\n",
    "        responses = {\n",
    "            \"llama\": chain_llama.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list')}),\n",
    "            \"mistral\": chain_mistral.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list')}),\n",
    "            \"gemma\": chain_gemma.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list')}),\n",
    "            \"phi\": chain_phi.invoke({\"desc\": df_members.iloc[:, :-1].to_dict(orient='list')}),\n",
    "        }\n",
    "\n",
    "        ### extract top-10s and explanations from output\n",
    "        vectors = {key: extract_numbers(ensure_list(res[\"recommendation\"])) for key, res in responses.items()}\n",
    "        explanations = {key: res[\"explanation\"] for key, res in responses.items()}\n",
    "\n",
    "        # generate top-10s using each social choice-based aggregation strategy\n",
    "        vectors[\"ADD\"] = extract_numbers(ADD(transform_df(df_members)))\n",
    "        vectors[\"MPL\"] = extract_numbers(MPL(transform_df(df_members)))\n",
    "        vectors[\"LMS\"] = extract_numbers(LMS(transform_df(df_members)))\n",
    "        vectors[\"APP\"] = extract_numbers(APP(transform_df(df_members)))\n",
    "\n",
    "        ## Creating random top-10 for the random baseline\n",
    "        item_columns = [col for col in df_members.columns if col not in [\"user_id\", \"groupId\"]]\n",
    "        vectors['random'] = extract_numbers(random.sample(item_columns, min(10, len(item_columns))))\n",
    "        vector_lengths = [len(v) for v in vectors.values()]\n",
    "\n",
    "        ## creating temporary dataframe to add to the previous iterations\n",
    "        if len(set(vector_lengths)) == 1:\n",
    "\n",
    "            # df with top-10s\n",
    "            df_temp = pd.DataFrame([{\n",
    "                \"groupId\": group,\n",
    "                \"group_size\": df_members[\"user_id\"].nunique(),\n",
    "                **{f\"vector_{key}\": vec for key, vec in vectors.items()} \n",
    "            }])\n",
    "            # df with explanations\n",
    "            df_e = pd.DataFrame([{\n",
    "                \"groupId\": group,\n",
    "                **{key.capitalize(): exp for key, exp in explanations.items()}  \n",
    "            }])\n",
    "            ## save new data to the files\n",
    "            df_temp.to_csv(result_file, mode='a', index=False, header=not result_exists)\n",
    "            df_e.to_csv(expl_file, mode='a', index=False, header=not expl_exists)\n",
    "            \n",
    "            # If it is the first run, the file now exists!\n",
    "            result_exists = expl_exists = True\n",
    "        else:\n",
    "            group+=1\n",
    "            print(vector_lengths) ### print if there are issues (one of the LLMs not returning 10 items?)\n",
    "            continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing group {group}: {e}\") ## print if other issues\n",
    "\n",
    "    group += 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
